{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction and Clustering\n",
    "\n",
    "Term frequency - inverse document frequency (tf-idf) is a method to evaluate how important is a word in a document. It is a model to transform textual representation of information into a vector-space model (VSM)\n",
    "\n",
    "VSM is a model representing textual information as a vector which:\n",
    "1.  could represent the importance of a term (tf–idf) or even the absence or;\n",
    "2. represent presence (Bag of Words) of a term in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency (tf-idf)\n",
    "\n",
    "The **term frequency** of a document $d$ with respect a term $t$ is defined as:\n",
    "$$\n",
    "    \\text{tf}(t, d) = \\sum_{\\hat t \\in d}\\mathbb{1}_{\\hat t = t}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec = CountVectorizer()\n",
    "# Dense representation: |D| x F\n",
    "train_docs = [\"this is a test\", \"this is another test\", \"that is the final test\", \"what is this about?\"]\n",
    "train_docs = [\"esta es una prueba\", \"esta es otra prueba\", \"esa fue la prueba final\", \"¿De qué es esto?\"]\n",
    "Mtf = count_vec.fit_transform(train_docs)\n",
    "Mtf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'esta': 3,\n",
       " 'es': 1,\n",
       " 'una': 11,\n",
       " 'prueba': 9,\n",
       " 'otra': 8,\n",
       " 'esa': 2,\n",
       " 'fue': 6,\n",
       " 'la': 7,\n",
       " 'final': 5,\n",
       " 'de': 0,\n",
       " 'qué': 10,\n",
       " 'esto': 4}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem with a a term frequency model is that is scales up frequent terms and scales down rare terms, which may be more informative than higher frequency terms. **Term frequency - inverse document frequency**, or tf-id, attempts to solve that by logarithmically scaling up rare terms and scaling down higher order terms.\n",
    "\n",
    "We define the inverse document frequency (**idf**) as:\n",
    "$$\n",
    "    \\text{idf}(t) = \\log \\frac{|D|}{1 + |\\{d:  t \\in \\ d\\}|}\n",
    "$$\n",
    "\n",
    "Where $|D|$ is the number of documents in the corpus and, $|\\{d:  t \\in \\ d\\}|$ is the number of documents containing the term $t$\n",
    "\n",
    "Finally, the tf-idf formula is defined as:\n",
    "\n",
    "$$\n",
    "    \\text{tf-idf}(t) = \\text{df}(t, d) \\times \\text{idf}(t)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esta\t1.51\n",
      "es\t1.00\n",
      "una\t1.92\n",
      "prueba\t1.22\n",
      "otra\t1.92\n",
      "esa\t1.92\n",
      "fue\t1.92\n",
      "la\t1.92\n",
      "final\t1.92\n",
      "de\t1.92\n",
      "qué\t1.92\n",
      "esto\t1.92\n"
     ]
    }
   ],
   "source": [
    "card_D = len(train_docs)\n",
    "idf = np.log((1 + card_D) / np.array([1 + np.sum([v in doc for doc in train_docs]) for v in count_vec.vocabulary_])) + 1\n",
    "\n",
    "for term, weight in zip(count_vec.vocabulary_, idf):\n",
    "    print(f\"{term}\\t{weight:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix $\\text{tf-idf}$ is defined as\n",
    "$$\n",
    "    M_{\\text{tf-idf}} = M_{tf} \\times M_{idf}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.319 0.    0.39  0.    0.    0.    0.    0.    0.611 0.    0.611]\n",
      " [0.    0.319 0.    0.39  0.    0.    0.    0.    0.611 0.611 0.    0.   ]\n",
      " [0.    0.    0.447 0.    0.    0.447 0.447 0.447 0.    0.447 0.    0.   ]\n",
      " [0.463 0.307 0.    0.    0.588 0.    0.    0.    0.    0.    0.588 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "Mtf_idf = Mtf @ np.identity(idf.shape[0]) *  idf\n",
    "# L2 normalizatoin\n",
    "Mtf_idf = Mtf_idf / norm(Mtf_idf, ord=2, axis=1).reshape(-1, 1)\n",
    "print(Mtf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the steps above using scikit-learn's `TfidfTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.409 0.    0.505 0.    0.    0.    0.    0.    0.409 0.    0.641]\n",
      " [0.    0.409 0.    0.505 0.    0.    0.    0.    0.641 0.409 0.    0.   ]\n",
      " [0.    0.    0.476 0.    0.    0.476 0.476 0.476 0.    0.304 0.    0.   ]\n",
      " [0.542 0.346 0.    0.    0.542 0.    0.    0.    0.    0.    0.542 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_trans = TfidfTransformer(norm=\"l2\")\n",
    "Mtf_idf = tfidf_trans.fit_transform(Mtf)\n",
    "print(Mtf_idf.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can make use of `CountVectorizer` and `TfidfTransformer` in one step using `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.409 0.    0.505 0.    0.    0.    0.    0.    0.409 0.    0.641]\n",
      " [0.    0.409 0.    0.505 0.    0.    0.    0.    0.641 0.409 0.    0.   ]\n",
      " [0.    0.    0.476 0.    0.    0.476 0.476 0.476 0.    0.304 0.    0.   ]\n",
      " [0.542 0.346 0.    0.    0.542 0.    0.    0.    0.    0.    0.542 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "tfv = TfidfVectorizer(norm=\"l2\", smooth_idf=True)\n",
    "tfv_matrix = tfv.fit_transform(train_docs)\n",
    "print(tfv_matrix.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure the distance between two documents we make use of the cosine similarity\n",
    "\n",
    "$$\n",
    "    \\cos \\theta = \\frac{a\\cdot b}{||a||_2\\cdot||b||_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.59 , 0.124, 0.141],\n",
       "       [0.59 , 1.   , 0.124, 0.141],\n",
       "       [0.124, 0.124, 1.   , 0.   ],\n",
       "       [0.141, 0.141, 0.   , 1.   ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.   , 0.59 , 0.124, 0.141],\n",
       "        [0.59 , 1.   , 0.124, 0.141],\n",
       "        [0.124, 0.124, 1.   , 0.   ],\n",
       "        [0.141, 0.141, 0.   , 1.   ]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since each row is already normalize, Mtfv @ Mtfv.T is equivalent to the\n",
    "# dot product between any two documents\n",
    "(tfv_matrix @ tfv_matrix.T).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization \n",
    "\n",
    "* *Stemming* usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes.\n",
    "* *Lemmatization* usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def spanish_stemmer(corpus, lang=\"spanish\"):\n",
    "    stemmer = SnowballStemmer(lang)\n",
    "    corpus_tokens = word_tokenize(re.sub(\"[^\\w\\s]\", \"\", corpus).lower(), language=lang)\n",
    "    return [stemmer.stem(w) for w in corpus_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['los', 'indic', 'dispon', 'al', 'segund', 'trimestr', 'de', '2018', 'sugier', 'que', 'la', 'econom', 'mundial', 'continu', 'expand', 'a', 'un', 'ritm', 'relat', 'elev']\n"
     ]
    }
   ],
   "source": [
    "test_text = (\"Los indicadores disponibles al segundo trimestre de 2018 sugieren que la \"\n",
    "             \"economía mundial continuó expandiéndose a un ritmo relativamente elevado\")\n",
    "print(spanish_stemmer(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.409 0.    0.505 0.    0.    0.    0.    0.    0.409 0.    0.641]\n",
      " [0.    0.409 0.    0.505 0.    0.    0.    0.    0.641 0.409 0.    0.   ]\n",
      " [0.    0.    0.476 0.    0.    0.476 0.476 0.476 0.    0.304 0.    0.   ]\n",
      " [0.542 0.346 0.    0.    0.542 0.    0.    0.    0.    0.    0.542 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "tf = TfidfVectorizer(tokenizer=spanish_stemmer)\n",
    "m_tfidf = tf.fit_transform(train_docs)\n",
    "print(m_tfidf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.59  0.124 0.141]\n",
      " [0.59  1.    0.124 0.141]\n",
      " [0.124 0.124 1.    0.   ]\n",
      " [0.141 0.141 0.    1.   ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = cosine_similarity(m_tfidf)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn, multivariate_normal\n",
    "from scipy.cluster.hierarchy import cophenet, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = multivariate_normal([5, 0], [[1, 0], [0, 1]], size=100)\n",
    "c2 = multivariate_normal([0, 5], [[1, 0], [0, 1]], size=100)\n",
    "clust = np.r_[c1, c2]\n",
    "\n",
    "plt.scatter(*clust.T, s=3)\n",
    "plt.grid(alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9949192988798035\n"
     ]
    }
   ],
   "source": [
    "clustering = linkage(similarity_matrix, metric=\"cosine\")\n",
    "c, _  = cophenet(clustering, pdist(similarity_matrix))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row resulting from the `linkage` function will have the following form:\n",
    "> `[idx1, idx2, distance, sample_count]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.122, 2.   ],\n",
       "       [3.   , 4.   , 0.695, 3.   ],\n",
       "       [2.   , 5.   , 0.73 , 4.   ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. http://blog.christianperone.com/2011/09/machine-learning-text-feature-extraction-tf-idf-part-i/\n",
    "2. https://sites.temple.edu/tudsc/2017/03/30/measuring-similarity-between-texts-in-python/\n",
    "3. https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n",
    "4. https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
