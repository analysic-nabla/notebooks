{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import PyPDF2\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from unidecode import unidecode\n",
    "from collections import deque\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 3\n"
     ]
    }
   ],
   "source": [
    "url = (\"http://www.banxico.org.mx/publicaciones-y-prensa/\"\n",
    "       \"anuncios-de-las-decisiones-de-politica-monetaria/\"\n",
    "       \"%7B759F9C79-B40F-CD69-E10F-C56C3265923A%7D.pdf\")\n",
    "r = requests.get(url)\n",
    "pdf_reader = PyPDF2.PdfFileReader(BytesIO(r.content))\n",
    "n_pages = pdf_reader.numPages\n",
    "print(f\"Number of pages: {n_pages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(corpus: str) -> str:\n",
    "    \"\"\"\n",
    "    Return \n",
    "    \"\"\"\n",
    "    corpus = corpus.replace(\"%\", \"pct\") # We want to keep percentage representations\n",
    "    corpus = re.sub(r\"([0-9]+)\\.([0-9]+)\", r\"\\1ppoint\\2\", corpus) # Replace decimal points\n",
    "    corpus = re.sub(\"[^\\w\\s]\", \"\", corpus) # Remove all non-white space or letters\n",
    "    corpus  = re.sub(\"[\\n\\s]+\", \" \", corpus) # Replace one or more spaces for only one space\n",
    "    corpus = corpus.replace(\"ppoint\", \".\")  # Put back percentage points\n",
    "    \n",
    "    return corpus.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Text\n",
    "pages = [pdf_reader.getPage(p).extractText() for p in range(n_pages)]\n",
    "text = unidecode(\" \".join(pages)).lower()\n",
    "text = clean_text(text)\n",
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look to make a sequence of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 15 de noviembre de 2018 comun',\n",
       " ' 15 de noviembre de 2018 comuni',\n",
       " '15 de noviembre de 2018 comunic',\n",
       " '5 de noviembre de 2018 comunica',\n",
       " ' de noviembre de 2018 comunicad',\n",
       " 'de noviembre de 2018 comunicado',\n",
       " 'e noviembre de 2018 comunicado ',\n",
       " ' noviembre de 2018 comunicado d',\n",
       " 'noviembre de 2018 comunicado de',\n",
       " 'oviembre de 2018 comunicado de ']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght = 30\n",
    "sequences = [text[ix-lenght: ix+1] for ix in range(lenght, len(text))]\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9071"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of sequences inside the dataset \n",
    "nseq = len(sequences); nseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  3, ..., 23, 31, 24],\n",
       "       [ 0,  3,  7, ..., 31, 24, 20],\n",
       "       [ 3,  7,  0, ..., 24, 20, 14],\n",
       "       ...,\n",
       "       [25, 29,  0, ..., 16, 30, 12],\n",
       "       [29,  0, 26, ..., 30, 12,  0],\n",
       "       [ 0, 26, 12, ..., 12,  0,  5]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "ch_ix = {c:i for i, c in enumerate(chars)}\n",
    "sequences_int = [[ch_ix[char] for char in seq] for seq in sequences]\n",
    "sequences_int = np.array(sequences_int)\n",
    "sequences_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the sequences above (the rows of the ndarray), have a length of `length + 1`, this is due the fact that the first `lenght ` elements will become the training dataset and the last value is the target character to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sequences_int[:,:-1], sequences_int[:, -1]\n",
    "\n",
    "X_train = to_categorical(X_train, num_classes=vocab_size)\n",
    "y_train = to_categorical(y_train, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 36)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 30, 36)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 75)                33600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                2736      \n",
      "=================================================================\n",
      "Total params: 36,336\n",
      "Trainable params: 36,336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_input = Input(X_train.shape[1:])\n",
    "X = LSTM(75)(X_input)\n",
    "X = Dense(vocab_size, activation=\"softmax\")(X)\n",
    "model = Model(inputs=X_input, outputs=X)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9071/9071 [==============================] - 20s 2ms/step - loss: 2.8445 - acc: 0.1752\n",
      "Epoch 2/100\n",
      "9071/9071 [==============================] - 17s 2ms/step - loss: 2.6138 - acc: 0.2410\n",
      "Epoch 3/100\n",
      "9071/9071 [==============================] - 18s 2ms/step - loss: 2.3698 - acc: 0.3017\n",
      "Epoch 4/100\n",
      "9071/9071 [==============================] - 18s 2ms/step - loss: 2.2282 - acc: 0.3366\n",
      "Epoch 5/100\n",
      "9071/9071 [==============================] - 18s 2ms/step - loss: 2.1405 - acc: 0.3587\n",
      "Epoch 6/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 2.0682 - acc: 0.3743\n",
      "Epoch 7/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 2.0156 - acc: 0.3887\n",
      "Epoch 8/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 1.9651 - acc: 0.4013\n",
      "Epoch 9/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 1.9222 - acc: 0.4124\n",
      "Epoch 10/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 1.8775 - acc: 0.4271\n",
      "Epoch 11/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 1.8386 - acc: 0.4373\n",
      "Epoch 12/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 1.8018 - acc: 0.4527\n",
      "Epoch 13/100\n",
      "9071/9071 [==============================] - 19s 2ms/step - loss: 1.7666 - acc: 0.4624\n",
      "Epoch 14/100\n",
      "4224/9071 [============>.................] - ETA: 10s - loss: 1.7380 - acc: 0.4732"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/model.h5\")\n",
    "with open(\"outputs/char_mapping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ch_ix, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"outputs/model.h5\")\n",
    "with open(\"outputs/char_mapping.pkl\", \"rb\") as f:\n",
    "    ch_ix = pickle.load(f)\n",
    "ix_ch = {val: char  for char, val in ch_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchars = len(ch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_txt = \"noviembre de 2018 comunicado de prensa de\"\n",
    "encoded = to_categorical([ch_ix[ch] for ch in in_txt], num_classes=nchars).reshape(1, -1, nchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(model.predict(encoded))\n",
    "ix_ch[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input.shape[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(seed_text, model, decoding, n_seq):\n",
    "    len_seq = model.input.shape[1].value\n",
    "    encoding = {val:char for char, val in decoding.items()}\n",
    "    n_chars = len(encoding)\n",
    "    text_seq = seed_text\n",
    "    for _ in range(n_seq):\n",
    "        encode = [decoding[ch] for ch in text_seq]\n",
    "        encode = pad_sequences([encode], maxlen=len_seq, padding=\"pre\")\n",
    "        encode = to_categorical(encode, num_classes=n_chars).reshape(1, -1, n_chars)\n",
    "        pred = np.argmax(model.predict(encode))\n",
    "        char = encoding[pred]\n",
    "        text_seq += char\n",
    "    return text_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la junta de gobierno esta a favor de con otivo por las posi la pol itica mantenticar las a 2019 la inclativo del economia de conticiones a catarias aciver con extancialente se argendo de contisus inacticas delmedcano de resis nicresi pora contenticas inacimosteres respuntaria la potribal para contiyan la polisicam entrencialecienos pr'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_txt = \"la junta de gobierno esta a favor de\"\n",
    "generate_sequence(in_txt, model, ch_ix, 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
